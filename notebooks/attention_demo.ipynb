{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf1a74f7-e3e6-41af-b018-62996a86607e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Imports\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ceb270b9-542e-44f8-b00d-b177d584a26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q:\n",
      " tensor([[ 1.5410, -0.2934, -2.1788,  0.5684],\n",
      "        [-1.0845, -1.3986,  0.4033,  0.8380]])\n",
      "K:\n",
      " tensor([[-0.7193, -0.4033, -0.5966,  0.1820],\n",
      "        [-0.8567,  1.1006, -1.0712,  0.1227]])\n",
      "V:\n",
      " tensor([[-0.5663,  0.3731, -0.8920, -1.5091],\n",
      "        [ 0.3704,  1.4565,  0.9398,  0.7748]])\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Create random Q,K,V\n",
    "torch.manual_seed(0)\n",
    "Q = torch.randn(2,4)\n",
    "K = torch.randn(2,4)\n",
    "V = torch.randn(2,4)\n",
    "\n",
    "print(\"Q:\\n\",Q)\n",
    "print(\"K:\\n\",K)\n",
    "print(\"V:\\n\",V)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1f7da31-71fd-4f21-93d8-d4d6976d8ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw scores (QK^T):\n",
      " tensor([[ 0.4134,  0.7606],\n",
      "        [ 1.2561, -0.9395]])\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Compute raw attention scores\n",
    "scores = torch.matmul(Q, K.T)\n",
    "print(\"Raw scores (QK^T):\\n\", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92cc0d68-a883-4707-a151-146d4f7f374c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled scores:\n",
      " tensor([[ 0.2067,  0.3803],\n",
      "        [ 0.6280, -0.4697]])\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Scale scores\n",
    "d_k = K.shape[-1]  # dimension of keys\n",
    "scaled_scores = scores / torch.sqrt(torch.tensor(d_k, dtype=torch.float32))\n",
    "print(\"Scaled scores:\\n\", scaled_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8528fd54-7ca9-4f20-8d59-a2b908dcb020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights:\n",
      " tensor([[0.4567, 0.5433],\n",
      "        [0.7498, 0.2502]])\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Softmax to get attention weights\n",
    "attn_weights = F.softmax(scaled_scores, dim=-1)\n",
    "print(\"Attention weights:\\n\", attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "083b1158-7fb7-4516-9883-7abac7ae8bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final attention output:\n",
      " tensor([[-0.0574,  0.9617,  0.1032, -0.2683],\n",
      "        [-0.3320,  0.6441, -0.4338, -0.9378]])\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Multiply weights with Values\n",
    "output = torch.matmul(attn_weights, V)\n",
    "print(\"Final attention output:\\n\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7de05f67-253f-45d8-b36e-7b1c2544ff4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa06095d-fbe5-4791-888e-8e87f4812331",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
